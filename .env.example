# Apex RAG System Environment Variables

# ============================================
# DATABASE CONFIGURATION (Self-Hosted)
# ============================================

# PostgreSQL (with pgvector) - Vector + Semantic Storage
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=apex
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_DB=apex_rag
POSTGRES_MIN_CONNECTIONS=2
POSTGRES_MAX_CONNECTIONS=10

# Neo4j Community Edition - Graph Storage
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password_here
NEO4J_DATABASE=neo4j

# ============================================
# LLM CONFIGURATION (External API)
# ============================================

# Provider: zai, openrouter, openai, or custom
LLM_PROVIDER=zai

# z.AI (default)
ZAI_API_KEY=your_zai_api_key_here

# OpenRouter (alternative)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# OpenAI (alternative)
OPENAI_API_KEY=your_openai_api_key_here

# Generic LLM API Key (fallback or for custom providers)
LLM_API_KEY=your_api_key_here

# Custom endpoint (for local models like Ollama, vLLM)
# LLM_BASE_URL=http://localhost:11434/v1
# LLM_MODEL=llama3

# LLM settings
LLM_TIMEOUT=60
LLM_MAX_RETRIES=3

# ============================================
# EMBEDDING MODEL (Self-Hosted)
# ============================================

# Local embedding model - no external API calls
EMBEDDING_MODEL=Alibaba-NLP/gte-modernbert-base
EMBEDDING_DIMENSION=768
EMBEDDING_MAX_SEQ_LENGTH=8192
EMBEDDING_DEVICE=auto  # Options: cpu, cuda, auto
EMBEDDING_NORMALIZE=true
# EMBEDDING_CACHE_DIR=./models  # Optional: custom model cache

# ============================================
# MCP SERVER CONFIGURATION
# ============================================

MCP_SERVER_NAME=apex-rag
MCP_LOG_LEVEL=INFO

# ============================================
# INGESTION PATHS
# ============================================

# Default directories for document/code ingestion
DOCS_INPUT_DIR=./data/input/docs
CODE_INPUT_DIR=./data/input/code
OUTPUT_DIR=./data/output
